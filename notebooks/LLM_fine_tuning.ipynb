{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzlbKw5u6KFX"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcn_2rq8Cc9R"
      },
      "source": [
        "We will work with the famous \"dialogsum\" dataset. It is made of dialogues that could happend between humans. All conversations have corresponding summaries.\n",
        "\n",
        "You can obtain more information [here](https://huggingface.co/datasets/knkarthick/dialogsum)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YM4giD9D5XDb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/julien/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/Users/julien/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "import torch\n",
        "import time\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYCwWOQc5kNT",
        "outputId": "7bd196b5-c802-4650-9f27-42ea994c4b31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 12460\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "\n",
        "dataset = load_dataset(huggingface_dataset_name)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oxKJRzJDWcZ"
      },
      "source": [
        "As we can see, the dataset is coming with everything we need: train, validation and test sets. With more than 12k training conversations, we have everything we need for fine-tuning our LLM.\n",
        "\n",
        "Below is an example of the first dialogue and its corresponding summary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2cvA0t655To",
        "outputId": "85234872-0dd4-49b5-c2f1-4b4ff1ab1851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the dialogue:\n",
            "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
            "#Person2#: I found it would be a good idea to get a check-up.\n",
            "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
            "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
            "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
            "#Person2#: Ok.\n",
            "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
            "#Person2#: Yes.\n",
            "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
            "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
            "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
            "#Person2#: Ok, thanks doctor.\n",
            "------------------------------------------------------------\n",
            "This is the summary:\n",
            "Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n"
          ]
        }
      ],
      "source": [
        "print(f\"This is the dialogue:\\n{dataset['train'][0]['dialogue']}\")\n",
        "print(\"---\"*20)\n",
        "print(f\"This is the summary:\\n{dataset['train'][0]['summary']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUFzcOKPEdk2"
      },
      "source": [
        "It is important to note that all summaries are human generated and will be our base for performance review of our model.\n",
        "Also, we should keep in mind that language is a complex topic, and of course we can never assure summaries are one hundred percent perfect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUAJ9-Cf6N9W"
      },
      "source": [
        "## Importing base Flan-T5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CoNIWyUE4bz"
      },
      "source": [
        "To start, we will load the Flan-T5 model designed by Google's team and first released in the paper *Scaling Instruction-Finetuned Language Models* (by HW Chung et al., 2022). Paper is available [here](https://arxiv.org/pdf/2210.11416) and you can consult module's documentation at HuggingFace dedicated [page](https://huggingface.co/docs/transformers/en/model_doc/flan-t5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sC3y7vlt58_O"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/julien/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name='google/flan-t5-base'\n",
        "\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQtyN93vFyGN"
      },
      "source": [
        "Out of curiosity, we will print below the number of parameters Flan-T5 is including. As you will see, numbers are quite outstanding with more than 200M parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6_9mC3V5-un",
        "outputId": "64ba2e58-f1a7-49c7-dcb2-144c6164d3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable model parameters: 247577856\n",
            "all model parameters: 247577856\n",
            "percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ],
      "source": [
        "def original_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "\n",
        "    for layer, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(original_model_parameters(original_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4dITnkuGXgp"
      },
      "source": [
        "Even though all parameters are trainable, it is obvious that training from scratch such a model is impossible for simple individuals like us. However, we will see later how to still effectively \"retrain\" the model to suit our needs.\n",
        "\n",
        "For now, let's test Flan-T5 on our dataset and ask for summaries of dialogues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDBhcR1c6Avx",
        "outputId": "f258e5d1-4138-44bf-a1a8-3bbe723d3557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the dialogue at index 14:\n",
            "#Person1#: What kind of music do you like listening to?\n",
            "#Person2#: I like music that has a fast beat and is lively, like dance music. You know, I go to a disco almost every week. Sometimes it's too loud though. You prefer classical music, don't you?\n",
            "#Person1#: Yes, I do. I find it very relaxing. I often listen to Mozart or Bach in the evening after a hard day at work.\n",
            "#Person2#: I must admit that I like several pieces of classical music. It's certainly more sophisticated that modern dance music.\n",
            "#Person1#: Classical music is supposed to be good for you brain. Research suggest that it makes your brain more active. Students who listen to classical music while studying perform better.\n",
            "#Person2#: Really? Perhaps I should listen to classical music often. I heard that listening to classical music is helpful in reducing stress.\n",
            "#Person1#: Yes. That's why I listen to it in the evenings. I usually play it as background music while I'm cooking or doing other housework.\n",
            "#Person2#: I'Ve got a few classical music CD's. I should follow your lead and increase my brian power.\n",
            "#Person1#: You can find plenty of recording on the internet too. You can listen to samples and then buy them very cheaply if you like them.\n",
            "#Person2#: That's a good idea. You should do the same with some music. You might find something you like. Classical music might make you clever, but dance might make you livelier and happier.\n",
            "#Person1#: That's true. There's clear evidence that people who listen to lively music are lively people. Music can influence a person's feeling and character.\n",
            "------------------------------------------------------------\n",
            "This is the corresponding summary:\n",
            "#Person2# likes dance music while #Person1# prefers classical music. #Person1# suggests #Person2# listen to more classical music because it can make the brain more active and reduce stress. #Person2# tells #Person1# classical music makes #Person2# clever, but dance makes #Person1# livelier and happier.\n"
          ]
        }
      ],
      "source": [
        "index = np.random.randint(100)\n",
        "\n",
        "dialogue = dataset[\"train\"][index][\"dialogue\"]\n",
        "summary = dataset[\"train\"][index][\"summary\"]\n",
        "\n",
        "print(f\"This is the dialogue at index {index}:\\n{dialogue}\")\n",
        "print(\"----\"*15)\n",
        "print(f\"This is the corresponding summary:\\n{summary}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM2nEK-IHMwX"
      },
      "source": [
        "First, we need to design a prompt template. We will use zero-shot inference, i.e. we will not provide any example of what we expect to the model. Feel free to compare performances by using one-shot or even few-shot inferences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WXmVV2sW6CaV"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "\n",
        "Summarize the following conversation:\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdlOuvf7HmZh"
      },
      "source": [
        "Now that we have our prompt, we must:\n",
        "\n",
        "1.   Tokenize the input using a transformer architecture so the model can understand what we are asking (see [*Attention Is All You Need*](https://arxiv.org/abs/1706.03762) (by A Vaswani et al., 2017) for more details on how transformers work.\n",
        "2.   Decode the output so **we** can read it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3eYefB2h6UNA"
      },
      "outputs": [],
      "source": [
        "input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = tokenizer.decode(original_model.generate(input[\"input_ids\"],\n",
        "                                                max_new_tokens=200)[0],\n",
        "                                                skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYxq1ckIcP8"
      },
      "source": [
        "Ok now that we have our prediction, let's compare it to the actual summary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkNvMiVk6Vrh",
        "outputId": "16a74628-9ec3-424a-f6da-5afbd25a7be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Prompt:\n",
            "\n",
            "\n",
            "Summarize the following conversation:\n",
            "#Person1#: What kind of music do you like listening to?\n",
            "#Person2#: I like music that has a fast beat and is lively, like dance music. You know, I go to a disco almost every week. Sometimes it's too loud though. You prefer classical music, don't you?\n",
            "#Person1#: Yes, I do. I find it very relaxing. I often listen to Mozart or Bach in the evening after a hard day at work.\n",
            "#Person2#: I must admit that I like several pieces of classical music. It's certainly more sophisticated that modern dance music.\n",
            "#Person1#: Classical music is supposed to be good for you brain. Research suggest that it makes your brain more active. Students who listen to classical music while studying perform better.\n",
            "#Person2#: Really? Perhaps I should listen to classical music often. I heard that listening to classical music is helpful in reducing stress.\n",
            "#Person1#: Yes. That's why I listen to it in the evenings. I usually play it as background music while I'm cooking or doing other housework.\n",
            "#Person2#: I'Ve got a few classical music CD's. I should follow your lead and increase my brian power.\n",
            "#Person1#: You can find plenty of recording on the internet too. You can listen to samples and then buy them very cheaply if you like them.\n",
            "#Person2#: That's a good idea. You should do the same with some music. You might find something you like. Classical music might make you clever, but dance might make you livelier and happier.\n",
            "#Person1#: That's true. There's clear evidence that people who listen to lively music are lively people. Music can influence a person's feeling and character.\n",
            "\n",
            "Summary:\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Baseline Human Summary:\n",
            "#Person2# likes dance music while #Person1# prefers classical music. #Person1# suggests #Person2# listen to more classical music because it can make the brain more active and reduce stress. #Person2# tells #Person1# classical music makes #Person2# clever, but dance makes #Person1# livelier and happier.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "LLM Summary - Zero Shot:\n",
            "Listen to classical music. Listen to dance music. Listen to classical music. Listen to dance music. Listen to classical music. Listen to dance music. Listen to classical music.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Input Prompt:\\n{prompt}\")\n",
        "print(\"-----\"*20)\n",
        "print(f\"Baseline Human Summary:\\n{summary}\")\n",
        "print(\"-----\"*20)\n",
        "print(f\"LLM Summary - Zero Shot:\\n{output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un-dG-idIiE7"
      },
      "source": [
        "What are your thoughts on this? It looks like the model is very straight to the point, and lacking details in its summary. It is like the summary is too short and missing some valuable informations.\n",
        "\n",
        "To get an idea of the model performance, we will compute its ROUGE score. This score is calculated as below (higher the better):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak_33yGjI5eW"
      },
      "source": [
        "$$ \\text{ROUGE-1} = \\frac{\\text{Unigram Matches}}{\\text{Total number of unigram in reference}} $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPT-F93wLFFZ"
      },
      "source": [
        "\n",
        "$$ \\text{ROUGE-2} = \\frac{\\text{Unigram Matches}}{\\text{Unigrams in Output}} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMckP6OjLJ-m"
      },
      "source": [
        "$$ \\text{ROUGE-L} = \\frac{\\text{Length of longest common subsequence}}{\\text{Total number of words in reference summaries}} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UKw8gUJLMe-"
      },
      "source": [
        "\n",
        "$$ \\text{ROUGE-Lsum} = \\frac{\\text{Total length of overlapping summary}}{\\text{Total length of reference summaries}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQfFS2AS6XWd",
        "outputId": "fe7e74a7-ab5d-45a8-eed9-38d0fcdb4f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.03977272727272727, 'rouge2': 0.0, 'rougeL': 0.03977272727272727, 'rougeLsum': 0.03977272727272727}\n"
          ]
        }
      ],
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=output,\n",
        "    references=summary[0:len(output)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEG4ryXCLP4f"
      },
      "source": [
        "Clearly, our model is not performing especially well: even though Flan-T5 was designed to solve various tasks, it is not necessarly especially well designed to produced summaries on the go. Let's see how we can improve its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_RUHeeU63pu"
      },
      "source": [
        "## Perform Parameter Efficient Fine-Tuning (PEFT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcP7A3zILugk"
      },
      "source": [
        "In this section we will implement Parameter Efficient Fine-Tuning (or PEFT).\n",
        "\n",
        "Full fine-tuning of large LLMs are challenging and very costly, which makes it hard to retrain a whole model. With PEFT, the idea is to freeze most of the layers of our model, and update only some of the layers. Various methods exist to do this such as (i) \"Selective\" (only fine-tune some parameters), (ii) \"Reparameterization\" (implement a low rank representation of the model), or (iii) \"Additive\" (add trainable layers or parameters to the model).\n",
        "\n",
        "In this section we will go with the second option and use the [LoRA method](https://huggingface.co/docs/diffusers/main/en/training/lora)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EgvxhX2L6c6s"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/julien/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
        "from peft import LoraConfig, get_peft_model, PeftModel, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,  # Rank of the submatrices\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")\n",
        "\n",
        "model_name = 'google/flan-t5-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# we create the PEFT model\n",
        "peft_model = get_peft_model(original_model, lora_config)\n",
        "\n",
        "# we define an output directory for the trained model - this is key as we will save the model to be able to reuse it later\n",
        "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "fb6c82a871a34e089fb2ba471357985e",
            "0f742c0657a44d80b0eca1e686fe1a12",
            "8049f399414a4085946aae31d0e68914",
            "7dc918a4a1924fd19c7a5f13d66a8fba",
            "63557b9adee54fee9cdbdbd53011b6c7",
            "7afe2396ff7148ce93974bf982be0b16",
            "2ca8e35f3e6a4fda9cdea5fbcb01906e",
            "f17949a36554483bb788f7dbebc414b9",
            "13cd9503bf7740809eb92db90a87c8da",
            "f0144ff5cb2b4badb4c79b44c7e3e850",
            "d82bb079f0854038a6fbc0803d00709d",
            "3dbfb28cc90e47f8a538248cf8f5e791",
            "e27106d3f67e49b492d9825cd8e6dbed",
            "09291137731b486e92b300d33d52a0d6",
            "4e7b4543976b405ca6bb9512a9fd7be1",
            "461d73c6560b4a9daa601ee5dfbb2a3e",
            "284fffa3d6bb4d50aab4520854eb0554",
            "d87d0cbf1dff496eb2710b2f86b144e6",
            "361e25d6dc4f45fbb80b8779a7e513b9",
            "49cacbc30c8d43f6b7a95fe1a4f0fbf0",
            "4cde5d0fe3aa4d27ab154c8a65525bd3",
            "9ee6b011a6f54f3998e92eff6a149423",
            "6b95b0bd58e14a5b901ca8fca1a77271",
            "56a687eee38340c788b4ad6cbd228ccf",
            "49506e50d1df48b783cbb0d820b952a7",
            "4808776d28fd416495d8299edcbd17ef",
            "7637d46f5e5347ec9872700a74a7237c",
            "86a20e3b58bc4b81a716ae21eab11f69",
            "ee17c1761e9940c7a34f940b4f83f907",
            "46fd7dc08a7546179648405b5f318870",
            "7ea33b5f9ca6476d99b118c9d7e68f0a",
            "fafd906850cd4a799d4fa5e8718c5ea2",
            "7a890bc06eef4bf79df72f7c25814f1f"
          ]
        },
        "id": "oa2Qtcf4_dgM",
        "outputId": "5ff3878b-78cd-47e5-c8e2-1db9b5475f42"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b8ad02d653141c9a0daa3c270cf7d76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/julien/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# we need to preprocess the dataset to correspond to LoRA expecations.\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples['dialogue']\n",
        "    targets = examples['summary']\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uGtkkGKJ74ci"
      },
      "outputs": [],
      "source": [
        "# Data collator for padding\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=original_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItryZYraNbhW"
      },
      "source": [
        "Now, we can design our training. Note that we minimized most of the options here in the sake of computation time. Feel free to play with these parameters to see how performance of the model changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSOi35Ya7MvR",
        "outputId": "aca67a90-8a47-48ec-a213-9b1551f4c1c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/julien/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "peft_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    auto_find_batch_size=True,\n",
        "    learning_rate=1e-3,\n",
        "    num_train_epochs=10,\n",
        "    logging_steps=10,\n",
        "    max_steps=100,\n",
        "    save_steps=10,\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "JmagtSgV8FcK",
        "outputId": "3fb70013-b967-426f-e3ec-e9e833d7e4cf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28d9e32613a04f969d084156069e7cc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# we train our new model\n",
        "peft_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB5lOkU0OGxb",
        "outputId": "6dc72267-d909-4c6f-ecdc-704db6fec4c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./peft-dialogue-summary-checkpoint-local/tokenizer_config.json',\n",
              " './peft-dialogue-summary-checkpoint-local/special_tokens_map.json',\n",
              " './peft-dialogue-summary-checkpoint-local/spiece.model',\n",
              " './peft-dialogue-summary-checkpoint-local/added_tokens.json',\n",
              " './peft-dialogue-summary-checkpoint-local/tokenizer.json')"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we save the fine-tuned model and its tokenizer for later use\n",
        "peft_model_path = \"./peft-dialogue-summary-checkpoint-local\"\n",
        "peft_trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye2G6HpC79fs"
      },
      "outputs": [],
      "source": [
        "# Set the device to GPU (or CPU if GPU is not available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Clearing any existing cache (if applicable) in case we run the code a multiple times and RAM is full\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_path)\n",
        "\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base').to(device)\n",
        "fine_tuned_model = PeftModel.from_pretrained(original_model, peft_model_path).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbxcTrLK-N25"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids.to(device)\n",
        "\n",
        "output_PEFT = tokenizer.decode(fine_tuned_model.model.generate(input_ids, max_new_tokens=100)[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2XLDARjOkcd"
      },
      "source": [
        "Ok now, let's see what are our outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBUKSrw8_qSK",
        "outputId": "a4206f7a-2fd1-42f4-c560-7f39308f3bd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Prompt:\n",
            "\n",
            "\n",
            "Summarize the following conversation:\n",
            "#Person1#: What kind of job do you intend to do?\n",
            "#Person2#: I want to do some management job since I have three-year's work history.\n",
            "#Person1#: What are your plans if you were hired?\n",
            "#Person2#: I would apply my specialty and experience to my job and gradually move up to the management level in this company. \n",
            "\n",
            "Summary:\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Baseline Human Summary:\n",
            "#Person2# tells #Person1# #Person2#'s ideal job and the job plan if hired.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Base Model Summary - Zero Shot:\n",
            "Ask the person to describe their career goals.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "PEFT Model Summary - Zero Shot:\n",
            "#Person2# wants to do some management job because he has three years' work history.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Input Prompt:\\n{prompt}\")\n",
        "print(\"-----\"*20)\n",
        "print(f\"Baseline Human Summary:\\n{summary}\")\n",
        "print(\"-----\"*20)\n",
        "print(f\"Base Model Summary - Zero Shot:\\n{output}\")\n",
        "print(\"-----\"*20)\n",
        "print(f\"PEFT Model Summary - Zero Shot:\\n{output_PEFT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcPPJYGTOiX2"
      },
      "source": [
        "It seems our PEFT model is performing slightly better than the base model thanks to our training. However, compared to the human summary, we could argue that the difference is still obvious.\n",
        "\n",
        "Let's score our model and compare performances with the base:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek2GlswB-L-u",
        "outputId": "b1a23aad-7232-42de-8578-1088eec8230e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.021739130434782608, 'rouge2': 0.0, 'rougeL': 0.021739130434782608, 'rougeLsum': 0.021739130434782608}\n",
            "--------------------------------------------------------------------------------\n",
            "PEFT MODEL:\n",
            "{'rouge1': 0.12162162162162163, 'rouge2': 0.0, 'rougeL': 0.12162162162162163, 'rougeLsum': 0.12162162162162163}\n"
          ]
        }
      ],
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "if len(output_PEFT) > len(summary):\n",
        "    output_PEFT = output_PEFT[:len(summary)]\n",
        "else:\n",
        "    summary = summary[:len(output_PEFT)]\n",
        "\n",
        "PEFT_model_results = rouge.compute(\n",
        "    predictions=output_PEFT,\n",
        "    references=summary,\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print(\"----\"*20)\n",
        "print(\"PEFT MODEL:\")\n",
        "print(PEFT_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShgHv9ooPQps"
      },
      "source": [
        "Numbers do the talking here: even if not perfect, our PEFT model is surclassing the base by far. This proves that with good parameters and enough training, PEFT can provide real good improvements and help us to design an LLM better suited to our use case."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09291137731b486e92b300d33d52a0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_361e25d6dc4f45fbb80b8779a7e513b9",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49cacbc30c8d43f6b7a95fe1a4f0fbf0",
            "value": 500
          }
        },
        "0f742c0657a44d80b0eca1e686fe1a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7afe2396ff7148ce93974bf982be0b16",
            "placeholder": "​",
            "style": "IPY_MODEL_2ca8e35f3e6a4fda9cdea5fbcb01906e",
            "value": "Map: 100%"
          }
        },
        "13cd9503bf7740809eb92db90a87c8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "284fffa3d6bb4d50aab4520854eb0554": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ca8e35f3e6a4fda9cdea5fbcb01906e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "361e25d6dc4f45fbb80b8779a7e513b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dbfb28cc90e47f8a538248cf8f5e791": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e27106d3f67e49b492d9825cd8e6dbed",
              "IPY_MODEL_09291137731b486e92b300d33d52a0d6",
              "IPY_MODEL_4e7b4543976b405ca6bb9512a9fd7be1"
            ],
            "layout": "IPY_MODEL_461d73c6560b4a9daa601ee5dfbb2a3e"
          }
        },
        "461d73c6560b4a9daa601ee5dfbb2a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46fd7dc08a7546179648405b5f318870": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4808776d28fd416495d8299edcbd17ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fafd906850cd4a799d4fa5e8718c5ea2",
            "placeholder": "​",
            "style": "IPY_MODEL_7a890bc06eef4bf79df72f7c25814f1f",
            "value": " 1500/1500 [00:00&lt;00:00, 1901.15 examples/s]"
          }
        },
        "49506e50d1df48b783cbb0d820b952a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46fd7dc08a7546179648405b5f318870",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ea33b5f9ca6476d99b118c9d7e68f0a",
            "value": 1500
          }
        },
        "49cacbc30c8d43f6b7a95fe1a4f0fbf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cde5d0fe3aa4d27ab154c8a65525bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7b4543976b405ca6bb9512a9fd7be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cde5d0fe3aa4d27ab154c8a65525bd3",
            "placeholder": "​",
            "style": "IPY_MODEL_9ee6b011a6f54f3998e92eff6a149423",
            "value": " 500/500 [00:00&lt;00:00, 1731.97 examples/s]"
          }
        },
        "56a687eee38340c788b4ad6cbd228ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a20e3b58bc4b81a716ae21eab11f69",
            "placeholder": "​",
            "style": "IPY_MODEL_ee17c1761e9940c7a34f940b4f83f907",
            "value": "Map: 100%"
          }
        },
        "63557b9adee54fee9cdbdbd53011b6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b95b0bd58e14a5b901ca8fca1a77271": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56a687eee38340c788b4ad6cbd228ccf",
              "IPY_MODEL_49506e50d1df48b783cbb0d820b952a7",
              "IPY_MODEL_4808776d28fd416495d8299edcbd17ef"
            ],
            "layout": "IPY_MODEL_7637d46f5e5347ec9872700a74a7237c"
          }
        },
        "7637d46f5e5347ec9872700a74a7237c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a890bc06eef4bf79df72f7c25814f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7afe2396ff7148ce93974bf982be0b16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc918a4a1924fd19c7a5f13d66a8fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0144ff5cb2b4badb4c79b44c7e3e850",
            "placeholder": "​",
            "style": "IPY_MODEL_d82bb079f0854038a6fbc0803d00709d",
            "value": " 12460/12460 [00:13&lt;00:00, 1256.66 examples/s]"
          }
        },
        "7ea33b5f9ca6476d99b118c9d7e68f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8049f399414a4085946aae31d0e68914": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f17949a36554483bb788f7dbebc414b9",
            "max": 12460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13cd9503bf7740809eb92db90a87c8da",
            "value": 12460
          }
        },
        "86a20e3b58bc4b81a716ae21eab11f69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee6b011a6f54f3998e92eff6a149423": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d82bb079f0854038a6fbc0803d00709d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d87d0cbf1dff496eb2710b2f86b144e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e27106d3f67e49b492d9825cd8e6dbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_284fffa3d6bb4d50aab4520854eb0554",
            "placeholder": "​",
            "style": "IPY_MODEL_d87d0cbf1dff496eb2710b2f86b144e6",
            "value": "Map: 100%"
          }
        },
        "ee17c1761e9940c7a34f940b4f83f907": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0144ff5cb2b4badb4c79b44c7e3e850": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17949a36554483bb788f7dbebc414b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fafd906850cd4a799d4fa5e8718c5ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb6c82a871a34e089fb2ba471357985e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f742c0657a44d80b0eca1e686fe1a12",
              "IPY_MODEL_8049f399414a4085946aae31d0e68914",
              "IPY_MODEL_7dc918a4a1924fd19c7a5f13d66a8fba"
            ],
            "layout": "IPY_MODEL_63557b9adee54fee9cdbdbd53011b6c7"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
