{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_20240704_150822.csv', 'dataset_20240704_151424.csv', 'dataset_20240704_151901.csv', 'dataset_20240704_152357.csv', 'dataset_20240704_152812.csv', 'dataset_20240704_154639.csv', 'dataset_20240704_155436.csv', 'dataset_20240704_160014.csv', 'dataset_20240704_160759.csv', 'dataset_20240704_161256.csv', 'dataset_20240704_162030.csv', 'dataset_20240704_164120.csv', 'dataset_20240704_165808.csv', 'dataset_20240704_172021.csv', 'dataset_20240704_173948.csv', 'dataset_20240704_175152.csv', 'dataset_20240704_180117.csv', 'dataset_20240704_181213.csv', 'dataset_20240704_182558.csv', 'dataset_20240704_184053.csv', 'dataset_20240704_185236.csv', 'dataset_20240704_190449.csv', 'dataset_20240704_191929.csv', 'dataset_20240704_192809.csv', 'dataset_20240704_193055.csv', 'dataset_20240704_193834.csv', 'dataset_20240704_194959.csv', 'dataset_20240704_200424.csv', 'dataset_20240704_201639.csv', 'dataset_20240704_202421.csv', 'dataset_20240704_203553.csv', 'dataset_20240704_203820.csv', 'dataset_20240704_204506.csv', 'dataset_20240704_205933.csv', 'dataset_20240704_211116.csv', 'dataset_20240704_212524.csv', 'dataset_20240704_213524.csv', 'dataset_20240704_215154.csv', 'dataset_20240704_221608.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "datasets = '../data/dataset'\n",
    "files_list = os.listdir(datasets)\n",
    "\n",
    "print(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_path</th>\n",
       "      <th>transcript</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/audio\\000000.mp3</td>\n",
       "      <td>\\n\\tON the north-east coast of Scotland, in th...</td>\n",
       "      <td>\\n        \\n\\tThe history of the family of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/audio\\000001.mp3</td>\n",
       "      <td>\\n\\tALLEYN was no where to be found. The Earl ...</td>\n",
       "      <td>\\n        \\n\\tThere is an attack and an impend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/audio\\000002.mp3</td>\n",
       "      <td>\\n\\tTHE Count was walking on the ramparts of t...</td>\n",
       "      <td>\\n        \\n\\tMalcolm reveals an important sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/audio\\000003.mp3</td>\n",
       "      <td>\\n\\tMEANWHILE the Earl remained a solitary pri...</td>\n",
       "      <td>\\n        \\n\\tMatilda falls into despair over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/audio\\000004.mp3</td>\n",
       "      <td>\\n\\tMARY, in the mean time, suffered all the t...</td>\n",
       "      <td>\\n        \\n\\tIdentities are revealed and the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 audio_path  \\\n",
       "0  ../data/audio\\000000.mp3   \n",
       "1  ../data/audio\\000001.mp3   \n",
       "2  ../data/audio\\000002.mp3   \n",
       "3  ../data/audio\\000003.mp3   \n",
       "4  ../data/audio\\000004.mp3   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  \\n\\tON the north-east coast of Scotland, in th...   \n",
       "1  \\n\\tALLEYN was no where to be found. The Earl ...   \n",
       "2  \\n\\tTHE Count was walking on the ramparts of t...   \n",
       "3  \\n\\tMEANWHILE the Earl remained a solitary pri...   \n",
       "4  \\n\\tMARY, in the mean time, suffered all the t...   \n",
       "\n",
       "                                             summary  \n",
       "0  \\n        \\n\\tThe history of the family of the...  \n",
       "1  \\n        \\n\\tThere is an attack and an impend...  \n",
       "2  \\n        \\n\\tMalcolm reveals an important sec...  \n",
       "3  \\n        \\n\\tMatilda falls into despair over ...  \n",
       "4  \\n        \\n\\tIdentities are revealed and the ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for file in files_list:\n",
    "    filepath = os.path.join(datasets, file)\n",
    "    df = pd.read_csv(filepath)\n",
    "    data = pd.concat([data, df], ignore_index=True)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>transcript</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000.mp3</td>\n",
       "      <td>../data/audio\\000000.mp3</td>\n",
       "      <td>\\n\\tON the north-east coast of Scotland, in th...</td>\n",
       "      <td>\\n        \\n\\tThe history of the family of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001.mp3</td>\n",
       "      <td>../data/audio\\000001.mp3</td>\n",
       "      <td>\\n\\tALLEYN was no where to be found. The Earl ...</td>\n",
       "      <td>\\n        \\n\\tThere is an attack and an impend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000002.mp3</td>\n",
       "      <td>../data/audio\\000002.mp3</td>\n",
       "      <td>\\n\\tTHE Count was walking on the ramparts of t...</td>\n",
       "      <td>\\n        \\n\\tMalcolm reveals an important sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000003.mp3</td>\n",
       "      <td>../data/audio\\000003.mp3</td>\n",
       "      <td>\\n\\tMEANWHILE the Earl remained a solitary pri...</td>\n",
       "      <td>\\n        \\n\\tMatilda falls into despair over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000004.mp3</td>\n",
       "      <td>../data/audio\\000004.mp3</td>\n",
       "      <td>\\n\\tMARY, in the mean time, suffered all the t...</td>\n",
       "      <td>\\n        \\n\\tIdentities are revealed and the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                audio_path  \\\n",
       "0  000000.mp3  ../data/audio\\000000.mp3   \n",
       "1  000001.mp3  ../data/audio\\000001.mp3   \n",
       "2  000002.mp3  ../data/audio\\000002.mp3   \n",
       "3  000003.mp3  ../data/audio\\000003.mp3   \n",
       "4  000004.mp3  ../data/audio\\000004.mp3   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  \\n\\tON the north-east coast of Scotland, in th...   \n",
       "1  \\n\\tALLEYN was no where to be found. The Earl ...   \n",
       "2  \\n\\tTHE Count was walking on the ramparts of t...   \n",
       "3  \\n\\tMEANWHILE the Earl remained a solitary pri...   \n",
       "4  \\n\\tMARY, in the mean time, suffered all the t...   \n",
       "\n",
       "                                             summary  \n",
       "0  \\n        \\n\\tThe history of the family of the...  \n",
       "1  \\n        \\n\\tThere is an attack and an impend...  \n",
       "2  \\n        \\n\\tMalcolm reveals an important sec...  \n",
       "3  \\n        \\n\\tMatilda falls into despair over ...  \n",
       "4  \\n        \\n\\tIdentities are revealed and the ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.insert(0,'id','')\n",
    "data['id'] = data.audio_path.str[-10:]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name='google/flan-t5-base'\n",
    "\n",
    "T5 = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples['transcript']\n",
    "    targets = examples['summary']\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [\n",
    "        f\"Summarize the following conversation.\\n\\n### Input:\\n{transcript}\\n\\n### Summary:\\n\"\n",
    "        for transcript in examples['transcript']\n",
    "    ]\n",
    "    \n",
    "    targets = examples['summary']\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8384bb582193402e80ab19e39c1f8442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/390 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guyet\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Prompt Example:\n",
      "Input Text:\n",
      " Summarize the following conversation. ### Input: ON the north-east coast of Scotland, in the most romantic part of the Highlands, stood the Castle of Athlin; an edifice built on the summit of a rock whose base was in the sea. This pile was venerable from its antiquity, and from its Gothic structure; but more venerable from the virtues which it enclosed. It was the residence of the still beautiful widow, and the children of the noble Earl of Athlin, who was slain by the hand of Malcolm, a neighbouring chief, proud, oppressive, revengeful; and still residing in all the pomp of feudal greatness, within a few miles of the castle of Athlin. Encroachment on the domain of Athlin, was the occasion of the animosity which subsisted between the chiefs. Frequent broils had happened between their clans, in which that of Athlin had generally been victorious. Malcolm, whose pride was touched by the defeat of his people; whose ambition was curbed by the authority, and whose greatness was rivalled by the power of the Earl, conceived for him that deadly hatred which opposition to its favourite passions naturally excites in a mind like his, haughty and unaccustomed to controul; and he meditated his destruction. He planned his purpose with all that address which so eminently marked his character, and in a battle which was attended by the chiefs of each party in person, he contrived, by a curious finesse, to entrap the Earl, accompanied by a small detachment, in his wiles, and there slew him. A general rout of his clan ensued, which was followed by a dreadful slaughter; and a few only escaped to tell the horrid catastrophe to Matilda. Overwhelmed by the news, and deprived of those numbers which would make revenge successful, Matilda forbore to sacrifice the lives of her few remaining people to a feeble attempt at retaliation, and she was constrained to endure in silence her sorrows and her injuries. Inconsolable for his death, Matilda had withdrawn from the public eye, into this ancient seat of feudal government, and there, in the bosom of her people and her family, had devoted herself to the education of her children. One son and one daughter were all that survived to her care, and their growing virtues promised to repay all her tenderness. Osbert was in his nineteenth year: nature had given him a mind ardent and susceptible, to which education had added refinement and expansion. The visions of genius were bright in his imagination, and his heart, unchilled by the touch of disappointment, glowed with all the warmth of benevolence. When first we enter on the theatre of the world, and begin to notice its features, young imagination heightens every scene, and the warm heart expands to all around it. The happy benevolence of our feelings prompts us to believe that every body is good, and excites our wonder why every body is not happy. We are fired with indignation at the recital of an act of injustice, and at the unfeeling vices of which we are told. At a tale of distress our tears flow a full tribute to pity: at a deed of virtue our heart unfolds, our soul aspires, we bless the action, and feel ourselves the doer. As we advance in life, imagination is compelled to relinquish a part of her sweet delirium; we are led reluctantly to truth through the paths of experience; and the objects of our fond attention are viewed with a severer eye. Here an altered scene appears; ‚Äî frowns where late were smiles; deep shades where late was sunshine: mean passions, or disgusting apathy stain the features of the principal figures. We turn indignant from a prospect so miserable, and court again the sweet illusions of our early days; but ah! they are fled for ever! Constrained, therefore, to behold objects in their more genuine hues, their deformity is by degrees less painful to us. The fine touch of moral susceptibility, by frequent irritation becomes callous; and too frequently we mingle with the world, till we are added to the number of its votaries. Mary, who was just seventeen, had the accomplishments of riper years, with the touching\n",
      "\n",
      "Summary Text:\n",
      " The history of the family of the Earl of Athlin and the ongoing feud with Malcolm is introduced. \n"
     ]
    }
   ],
   "source": [
    "example = tokenized_dataset[0]\n",
    "input_text = tokenizer.decode(example['input_ids'], skip_special_tokens=True)\n",
    "summary_text = tokenizer.decode(example['labels'], skip_special_tokens=True)\n",
    "\n",
    "print(\"Training Prompt Example:\")\n",
    "print(\"Input Text:\\n\", input_text)\n",
    "print(\"\\nSummary Text:\\n\", summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Model Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Peft Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(T5, lora_config)\n",
    "\n",
    "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=T5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guyet\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = [[(l if l != -100 else tokenizer.pad_token_id) for l in label] for label in labels]\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=100,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    save_steps=10_000,\n",
    "    eval_steps=10_000,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=200,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Clearing any existing cache (if applicable) in case we run the code a multiple times and RAM is full\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a77977e2fa40d4b0cd3409e7b6fbb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4734, 'grad_norm': 0.55859375, 'learning_rate': 0.0009000000000000001, 'epoch': 0.23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2200c582a5a24ddaba13343fa915a315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4270832538604736, 'eval_runtime': 25.6343, 'eval_samples_per_second': 1.521, 'eval_steps_per_second': 0.195, 'epoch': 0.23}\n",
      "{'loss': 2.4773, 'grad_norm': 0.8828125, 'learning_rate': 0.0008, 'epoch': 0.45}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb6edd9cf2c4773b1c7cd5e26c52e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.427884578704834, 'eval_runtime': 25.7856, 'eval_samples_per_second': 1.512, 'eval_steps_per_second': 0.194, 'epoch': 0.45}\n",
      "{'loss': 2.5531, 'grad_norm': 0.62109375, 'learning_rate': 0.0007, 'epoch': 0.68}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481a41438b824f638b4f39b1fbc37a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4054486751556396, 'eval_runtime': 25.4291, 'eval_samples_per_second': 1.534, 'eval_steps_per_second': 0.197, 'epoch': 0.68}\n",
      "{'loss': 2.4133, 'grad_norm': 0.70703125, 'learning_rate': 0.0006, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae108f797c1f4c62a049138339e998ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3994390964508057, 'eval_runtime': 25.4482, 'eval_samples_per_second': 1.533, 'eval_steps_per_second': 0.196, 'epoch': 0.91}\n",
      "{'loss': 2.4172, 'grad_norm': 0.875, 'learning_rate': 0.0005, 'epoch': 1.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b41c7ef3ab14c24b38cc112c0123cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.399038553237915, 'eval_runtime': 30.7231, 'eval_samples_per_second': 1.269, 'eval_steps_per_second': 0.163, 'epoch': 1.14}\n",
      "{'loss': 2.3328, 'grad_norm': 0.92578125, 'learning_rate': 0.0004, 'epoch': 1.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ad53f02cfb4dedb9e92b7f22e95c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3866186141967773, 'eval_runtime': 25.452, 'eval_samples_per_second': 1.532, 'eval_steps_per_second': 0.196, 'epoch': 1.36}\n",
      "{'loss': 2.3523, 'grad_norm': 0.7421875, 'learning_rate': 0.0003, 'epoch': 1.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d3cb1261bc4c979cf96eb3251e097d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3890223503112793, 'eval_runtime': 25.4191, 'eval_samples_per_second': 1.534, 'eval_steps_per_second': 0.197, 'epoch': 1.59}\n",
      "{'loss': 2.4328, 'grad_norm': 0.87109375, 'learning_rate': 0.0002, 'epoch': 1.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68de187c494b4ecab3e537e8583f5aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.379807710647583, 'eval_runtime': 25.2805, 'eval_samples_per_second': 1.543, 'eval_steps_per_second': 0.198, 'epoch': 1.82}\n",
      "{'loss': 2.4172, 'grad_norm': 0.59765625, 'learning_rate': 0.0001, 'epoch': 2.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258cb3b376a4452c97027f46c8ed750f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3669872283935547, 'eval_runtime': 25.324, 'eval_samples_per_second': 1.54, 'eval_steps_per_second': 0.197, 'epoch': 2.05}\n",
      "{'loss': 2.2898, 'grad_norm': 0.58203125, 'learning_rate': 0.0, 'epoch': 2.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b01982ac6548c4a9d4e5c951c604e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.364182710647583, 'eval_runtime': 25.3438, 'eval_samples_per_second': 1.539, 'eval_steps_per_second': 0.197, 'epoch': 2.27}\n",
      "{'train_runtime': 1601.6538, 'train_samples_per_second': 0.499, 'train_steps_per_second': 0.062, 'train_loss': 2.4159375, 'epoch': 2.27}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=2.4159375, metrics={'train_runtime': 1601.6538, 'train_samples_per_second': 0.499, 'train_steps_per_second': 0.062, 'total_flos': 1101548300009472.0, 'train_loss': 2.4159375, 'epoch': 2.2727272727272725})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./peft-t5-summary\\\\tokenizer_config.json',\n",
       " './peft-t5-summary\\\\special_tokens_map.json',\n",
       " './peft-t5-summary\\\\spiece.model',\n",
       " './peft-t5-summary\\\\added_tokens.json',\n",
       " './peft-t5-summary\\\\tokenizer.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_path = \"./peft-t5-summary\"\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Clearing any existing cache (if applicable) in case we run the code a multiple times and RAM is full\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_path)\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base').to(device)\n",
    "fine_tuned_model = PeftModel.from_pretrained(original_model, peft_model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_TO_SUMMARIZE = data['transcript'][0]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "\n",
    "Summarize the following conversation:\n",
    "{ARTICLE_TO_SUMMARIZE}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids.to(device)\n",
    "output_PEFT = tokenizer.decode(fine_tuned_model.model.generate(input_ids, max_new_tokens=100)[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "{'rouge1': 0.08163265306122448, 'rouge2': 0.0, 'rougeL': 0.08163265306122448, 'rougeLsum': 0.08163265306122448}\n"
     ]
    }
   ],
   "source": [
    "summary = data['summary'][0]\n",
    "\n",
    "if len(output_PEFT) > len(summary):\n",
    "    output_PEFT = output_PEFT[:len(summary)]\n",
    "else:\n",
    "    summary = summary[:len(output_PEFT)]\n",
    "\n",
    "PEFT_model_results = rouge.compute(\n",
    "    predictions=output_PEFT,\n",
    "    references=summary,\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print(\"----\"*20)\n",
    "print(\"PEFT MODEL:\")\n",
    "print(PEFT_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_T5 = tokenizer.decode(T5.generate(input_ids, max_new_tokens=100)[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "ORIGINAL TEXT:\n",
      "\n",
      "\tON the north-east coast of Scotland, in the most romantic part of the Highlands, stood the Castle of Athlin; an edifice built on the summit of a rock whose base was in the sea. This pile was venerable from its antiquity, and from its Gothic structure; but more venerable from the virtues which it enclosed. It was the residence of the still beautiful widow, and the children of the noble Earl of Athlin, who was slain by the hand of Malcolm, a neighbouring chief, proud, oppressive, revengeful; and still residing in all the pomp of feudal greatness, within a few miles of the castle of Athlin. Encroachment on the domain of Athlin, was the occasion of the animosity which subsisted between the chiefs. Frequent broils had happened between their clans, in which that of Athlin had generally been victorious. Malcolm, whose pride was touched by the defeat of his people; whose ambition was curbed by the authority, and whose greatness was rivalled by the power of the Earl, conceived for him that deadly hatred which opposition to its favourite passions naturally excites in a mind like his, haughty and unaccustomed to controul; and he meditated his destruction. He planned his purpose with all that address which so eminently marked his character, and in a battle which was attended by the chiefs of each party in person, he contrived, by a curious finesse, to entrap the Earl, accompanied by a small detachment, in his wiles, and there slew him. A general rout of his clan ensued, which was followed by a dreadful slaughter; and a few only escaped to tell the horrid catastrophe to Matilda. Overwhelmed by the news, and deprived of those numbers which would make revenge successful, Matilda forbore to sacrifice the lives of her few remaining people to a feeble attempt at retaliation, and she was constrained to endure in silence her sorrows and her injuries. \n",
      "\tInconsolable for his death, Matilda had withdrawn from the public eye, into this ancient seat of feudal government, and there, in the bosom of her people and her family, had devoted herself to the education of her children. One son and one daughter were all that survived to her care, and their growing virtues promised to repay all her tenderness. Osbert was in his nineteenth year: nature had given him a mind ardent and susceptible, to which education had added refinement and expansion. The visions of genius were bright in his imagination, and his heart, unchilled by the touch of disappointment, glowed with all the warmth of benevolence. \n",
      "\tWhen first we enter on the theatre of the world, and begin to notice its features, young imagination heightens every scene, and the warm heart expands to all around it. The happy benevolence of our feelings prompts us to believe that every body is good, and excites our wonder why every body is not happy. We are fired with indignation at the recital of an act of injustice, and at the unfeeling vices of which we are told. At a tale of distress our tears flow a full tribute to pity: at a deed of virtue our heart unfolds, our soul aspires, we bless the action, and feel ourselves the doer. As we advance in life, imagination is compelled to relinquish a part of her sweet delirium; we are led reluctantly to truth through the paths of experience; and the objects of our fond attention are viewed with a severer eye. Here an altered scene appears; ‚Äî frowns where late were smiles; deep shades where late was sunshine: mean passions, or disgusting apathy stain the features of the principal figures. We turn indignant from a prospect so miserable, and court again the sweet illusions of our early days; but ah! they are fled for ever! Constrained, therefore, to behold objects in their more genuine hues, their deformity is by degrees less painful to us. The fine touch of moral susceptibility, by frequent irritation becomes callous; and too frequently we mingle with the world, till we are added to the number of its votaries. \n",
      "\tMary, who was just seventeen, had the accomplishments of riper years, with the touching simplicity of youth. The graces of her person were inferior only to those of her mind, which illumined her countenance with inimitable expression. \n",
      "\tTwelve years had now elapsed since the death of the Earl, and time had blunted the keen edge of sorrow. Matilda‚Äôs grief had declined into a gentle, and not unpleasing melancholy, which gave a soft and interesting shade to the natural dignity of her character. Hitherto her attention had been solely directed towards rearing those virtues which nature had planted with so liberal a hand in her children, and which, under the genial influence of her eye, had flourished and expanded into beauty and strength. A new hope, and new solicitudes, now arose in her breast; these dear children were arrived at an age, dangerous from its tender susceptibility, and from the influence which imagination has at that time over the passions. Impressions would soon be formed which would stamp their destiny for life. The anxious mother lived but in her children, and she had yet another cause of apprehension. \n",
      "\tWhen Osbert learned the story of his father‚Äôs death, his young heart glowed to avenge the deed. The late Earl, who had governed with the real dignity of power, was adored by his clan; they were eager to revenge his injuries; but oppressed by the generous compassion of the Countess, their murmurs sunk into silence: yet they fondly cherished the hope that their young Lord would one day lead them on to conquest and revenge. The time was now come when they looked to see this hope, the solace of many a cruel moment, realized. The tender fears of a mother would not suffer Matilda to risque the chief of her last remaining comforts. She forbade Osbert to engage. He submitted in silence, and endeavored by application to his favourite studies, to stifle the emotions which roused him to aims. He excelled in the various accomplishments of his rank, but chiefly in the martial exercises, for they were congenial to the nobility of his soul, and he had a secret pleasure in believing that they would one time assist him to do justice to the memory of his dead father. His warm imagination directed him to poetry, and he followed where she led. He loved to wander among the romantic scenes of the Highlands, where the wild variety of nature inspired him with all the enthusiasm of his favourite art. He delighted in the terrible and in the grand, more than in the softer landscape; and, wrapt in the bright visions of fancy, would often lose himself in awful solitudes. \n",
      "\tIt was in one of these rambles, that having strayed for some miles over hills covered with heath, from whence the eye was presented with only the bold outlines of uncultivated nature, rocks piled on rocks, cataracts and vast moors unmarked by the foot of traveller, he lost the path which he had himself made; he looked in vain for the objects which had directed him, and his heart, for the first time, felt the repulse of fear. No vestige of a human being was to be seen, and the dreadful silence of the place was interrupted only by the roar of distant torrents, and by the screams of the birds which flew over his head. He shouted, and his voice was answered only by the deep echoes of the mountains. He remained for some time in a silent dread not wholly unpleasing, but which was soon heightened to a degree of terror not to be endured; and he turned his steps backward, forlorn, and dejected. His memory gave him back no image of the past; having wandered some time, he came to a narrow pass, which he entered, overcome with fatigue and fruitless search: he had not advanced far, when an abrupt opening in the rock suddenly presented him with a view of the most beautifully romantic spot he had ever seen. It was a valley almost surrounded by a barrier of wild rocks, whose base was shaded with thick woods of pine and fir. A torrent, which tumbled from the heights, and was seen between the woods, rushed with amazing impetuosity into a fine lake which flowed through the vale, and was lost in the deep recesses of the mountains. Herds of cattle grazed in the bottom, and the delighted eyes of Osbert were once more blessed with the sight of human dwellings. Far on the margin of the stream were scattered a few neat cottages. His heart was so gladdened at the prospect, that he forgot he had yet the way to find which led to this Elysian vale. He was just awakened to this distressing reality, when his attention was once more engaged by the manly figure of a young Highland peasant, who advanced towards him with an air of benevolence, and, having learned his distress, offered to conduct him to his cottage. Osbert accepted the invitation, and they wound down the hill, through an obscure and intricate path, together. They arrived at one of the cottages which the Earl had observed from the height; they entered, and the peasant presented his guest to a venerable old Highlander, his father. Refreshments were spread on the table by a pretty young girl, and Osbert, after having partook of them and rested awhile, departed, accompanied by Alleyn, the young peasant, who had offered to be his guide. The length of the walk was beguiled by conversation. Osbert was interested by discovering in his companion a dignity of thought, and a course of sentiment similar to his own. On their way, they passed at some distance the castle of Dunbayne. This object gave to Osbert a bitter reflection, and drew from him a deep sigh. Alleyn made observations on the bad policy of oppression in a chief, and produced as an instance the Baron Malcolm. These lands, said he, are his, and they are scarcely sufficient to support his wretched people, who, sinking under severe exactions, suffer to lie uncultivated, tracts which would otherwise add riches to their Lord. His clan, oppressed by their burdens, threaten to rise and do justice to themselves by force of arms. The Baron, in haughty confidence, laughs at their defiance, and is insensible to his danger: for should an insurrection happen, there are other clans who would eagerly join in his destruction, and punish with the same weapon the tyrant and the murderer. Surprized at the bold independence of these words, delivered with uncommon energy, the heart of Osbert beat quick, and ‚ÄúO God! my father!‚Äù burst from his lips. Alleyn stood aghast! uncertain of the effect which his speech had produced; in an instant the whole truth flashed upon his mind: he beheld the son of the Lord whom he had been taught to love, and whose sad story had been impressed upon his heart in the early days of childhood; he sunk at his feet, and embraced his knees with a romantic ardor. The young Earl raised him from the ground, and the following words relieved him from his astonishment, and filled his eyes with tears of mingled joy and sorrow: ‚ÄúThere are other clans as ready as your own to avenge the wrongs of the noble Earl of Athlin; the Fitz‚ÄìHenrys were ever friends to virtue.‚Äù The countenance of the youth, while he spoke, was overspread with the glow of conscious dignity, and his eyes were animated with the pride of virtue. ‚Äî The breast of Osbert kindled with noble purpose, but the image of his weeping mother crossed his mind, and checked the ardor of the impulse. ‚ÄúA time may come my friend,‚Äù said he, ‚Äúwhen your generous zeal will be accepted with the warmth of gratitude it deserves. Particular circumstances will not suffer me, at present, to say more.‚Äù The warm attachment of Alleyn to his father sunk deep in his heart. \n",
      "\tIt was evening before they reached the castle, and Alleyn remained the Earl‚Äôs guest for that night.\n",
      "------------------------------------------------------------\n",
      "HUMAN SUMMARY:\n",
      "\n",
      "        \n",
      "\tThe history of the family of the Earl of Athlin and the ongoing feud with Malcolm is introduced.      \n",
      "------------------------------------------------------------\n",
      "ORIGINAL MODEL SUMMARY:\n",
      "a strong desire to be a hero.\n",
      "------------------------------------------------------------\n",
      "FINE-TUNED MODEL SUMMARY:\n",
      "A story of the life of the noble Earl of Athlin. \n"
     ]
    }
   ],
   "source": [
    "dash_line = \"----\"*15\n",
    "\n",
    "print(dash_line)\n",
    "print(\"ORIGINAL TEXT:\")\n",
    "print(data['transcript'][0])\n",
    "\n",
    "print(dash_line)\n",
    "print(\"HUMAN SUMMARY:\")\n",
    "print(data['summary'][0])\n",
    "\n",
    "print(dash_line)\n",
    "print(\"ORIGINAL MODEL SUMMARY:\")\n",
    "print(output_T5)\n",
    "\n",
    "print(dash_line)\n",
    "print(\"FINE-TUNED MODEL SUMMARY:\")\n",
    "print(output_PEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
